# ML Service êµ¬ì¡° ë° ì›Œí¬í”Œë¡œìš° ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [í˜„ì¬ êµ¬ì¡°](#í˜„ì¬-êµ¬ì¡°)
3. [ì˜¤ëŠ˜ ì§„í–‰í•œ ì‘ì—…](#ì˜¤ëŠ˜-ì§„í–‰í•œ-ì‘ì—…)
4. [ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ì„¤ëª…](#ì£¼ìš”-ì»´í¬ë„ŒíŠ¸-ì„¤ëª…)
5. [ìƒˆë¡œìš´ CSV ë°ì´í„° ì—°ë™ ì›Œí¬í”Œë¡œìš°](#ìƒˆë¡œìš´-csv-ë°ì´í„°-ì—°ë™-ì›Œí¬í”Œë¡œìš°)
6. [ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°](#ë¨¸ì‹ ëŸ¬ë‹-íŒŒì´í”„ë¼ì¸-êµ¬ì¡°)
7. [API ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„ ê°€ì´ë“œ](#api-ì—”ë“œí¬ì¸íŠ¸-ì„¤ê³„-ê°€ì´ë“œ)

---

## ê°œìš”

`mlservice`ëŠ” ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ê³  í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ í†µí•© ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. 
ê° ë°ì´í„°ì…‹ì€ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, FastAPIë¥¼ í†µí•´ REST APIë¡œ ì œê³µë©ë‹ˆë‹¤.

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

- **ëª¨ë“ˆí™”**: ê° ë°ì´í„°ì…‹(Titanic, Culture ë“±)ì€ ë…ë¦½ì ì¸ í´ë”ë¡œ ë¶„ë¦¬
- **ì¼ê´€ì„±**: ëª¨ë“  ë°ì´í„°ì…‹ì€ ë™ì¼í•œ êµ¬ì¡°(Dataset, Model, Method, Service, Router)ë¥¼ ë”°ë¦„
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ì¶”ê°€ ì‹œ ê¸°ì¡´ êµ¬ì¡°ë¥¼ ë³µì‚¬í•˜ì—¬ ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥
- **ì¬ì‚¬ìš©ì„±**: ê³µí†µ ìœ í‹¸ë¦¬í‹°ì™€ ë² ì´ìŠ¤ í´ë˜ìŠ¤ë¥¼ í†µí•œ ì½”ë“œ ì¬ì‚¬ìš©

---

## í˜„ì¬ êµ¬ì¡°

```
mlservice/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                          # FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”‚
â”‚   â”œâ”€â”€ titanic/                         # íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ titanic_dataset.py          # ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ë°ì´í„° êµ¬ì¡° ì •ì˜)
â”‚   â”‚   â”œâ”€â”€ titanic_model.py            # ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ titanic_method.py           # ë°ì´í„° ì „ì²˜ë¦¬ ë©”ì„œë“œ
â”‚   â”‚   â”œâ”€â”€ titanic_service.py          # ML íŒŒì´í”„ë¼ì¸ ì„œë¹„ìŠ¤
â”‚   â”‚   â”œâ”€â”€ router.py                   # FastAPI ë¼ìš°í„° (API ì—”ë“œí¬ì¸íŠ¸)
â”‚   â”‚   â”œâ”€â”€ train.csv                   # í•™ìŠµ ë°ì´í„°
â”‚   â”‚   â””â”€â”€ test.csv                    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚   â”‚
â”‚   â””â”€â”€ culture/                         # ë¬¸í™” ë°ì´í„°ì…‹ ëª¨ë“ˆ (ì¤€ë¹„ ì¤‘)
â”‚       â””â”€â”€ culture.csv
â”‚
â”œâ”€â”€ docker-compose.yaml                  # ë…ë¦½ ì‹¤í–‰ìš© Docker Compose
â”œâ”€â”€ Dockerfile                           # ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ íŒŒì¼
â”œâ”€â”€ requirements.txt                     # Python íŒ¨í‚¤ì§€ ì˜ì¡´ì„±
â”œâ”€â”€ README.md                            # ì„œë¹„ìŠ¤ ì„¤ëª…ì„œ
â”œâ”€â”€ POSTMAN_TEST_GUIDE.md               # API í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ
â””â”€â”€ ML_Service_Titanic_API.postman_collection.json  # Postman ì»¬ë ‰ì…˜
```

---

## ì˜¤ëŠ˜ ì§„í–‰í•œ ì‘ì—…

### 1. ê¸°ì¡´ êµ¬ì¡° ë¬¸ì œì 

**ì´ì „ êµ¬ì¡° (ë¬¸ì œì )**:
```
mlservice/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ datasets.py        # ëª¨ë“  ë°ì´í„°ì…‹ì´ í•œ íŒŒì¼ì—
â”‚   â”œâ”€â”€ model.py           # Pydantic ëª¨ë¸ë§Œ ì¡´ì¬
â”‚   â”œâ”€â”€ service.py         # CRUDë§Œ ì¡´ì¬, ML íŒŒì´í”„ë¼ì¸ ì—†ìŒ
â”‚   â””â”€â”€ titanic/
â”‚       â”œâ”€â”€ router.py
â”‚       â”œâ”€â”€ train.csv
â”‚       â””â”€â”€ test.csv
```

**ë¬¸ì œì **:
- ë°ì´í„°ì…‹ í´ë˜ìŠ¤ê°€ í†µí•©ë˜ì–´ ìˆì–´ ê° ë°ì´í„°ì…‹ ê´€ë¦¬ ì–´ë ¤ì›€
- ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì´ ì—†ìŒ
- ì „ì²˜ë¦¬, ëª¨ë¸ë§, í•™ìŠµ, í‰ê°€ ë“±ì˜ ë‹¨ê³„ê°€ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ
- ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ì¶”ê°€ ì‹œ êµ¬ì¡°ê°€ ë¶ˆëª…í™•í•¨

### 2. ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ê°œì„ 

**ê°œì„ ëœ êµ¬ì¡°**:
```
mlservice/
â””â”€â”€ app/
    â””â”€â”€ titanic/                      # ê° ë°ì´í„°ì…‹ì€ ë…ë¦½ ëª¨ë“ˆ
        â”œâ”€â”€ titanic_dataset.py        # ë°ì´í„° êµ¬ì¡° ë° getter/setter
        â”œâ”€â”€ titanic_model.py          # ML ëª¨ë¸ (RandomForest ë“±)
        â”œâ”€â”€ titanic_method.py         # ì „ì²˜ë¦¬ ë©”ì„œë“œ
        â”œâ”€â”€ titanic_service.py        # ML íŒŒì´í”„ë¼ì¸ (5ë‹¨ê³„)
        â”œâ”€â”€ router.py                 # API ì—”ë“œí¬ì¸íŠ¸
        â”œâ”€â”€ train.csv
        â””â”€â”€ test.csv
```

**ê°œì„  ì‚¬í•­**:
- âœ… ê° ë°ì´í„°ì…‹ì´ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ë¶„ë¦¬
- âœ… ML íŒŒì´í”„ë¼ì¸ 5ë‹¨ê³„ êµ¬ì¡° í™•ë¦½ (ì „ì²˜ë¦¬ â†’ ëª¨ë¸ë§ â†’ í•™ìŠµ â†’ í‰ê°€ â†’ ì œì¶œ)
- âœ… ë°ì´í„° ê´€ë¦¬ì™€ ML ë¡œì§ ë¶„ë¦¬
- âœ… í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡° (ìƒˆ ë°ì´í„°ì…‹ ì¶”ê°€ ìš©ì´)

### 3. íŒŒì¼ë³„ ì—­í•  ì¬ì •ì˜

| íŒŒì¼ëª… | ì—­í•  | ì£¼ìš” ë‚´ìš© |
|--------|------|----------|
| `titanic_dataset.py` | ë°ì´í„° êµ¬ì¡° ì •ì˜ | - DataFrameì„ ë‹´ëŠ” ì»¨í…Œì´ë„ˆ í´ë˜ìŠ¤<br>- íŒŒì¼ ê²½ë¡œ ê´€ë¦¬ (dname, sname)<br>- train/test ë°ì´í„° ì €ì¥<br>- ID/Label ì»¬ëŸ¼ ì •ì˜ |
| `titanic_model.py` | ML ëª¨ë¸ ì •ì˜ | - ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤<br>- RandomForest, XGBoost ë“±<br>- ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • |
| `titanic_method.py` | ì „ì²˜ë¦¬ ë©”ì„œë“œ | - `new_model()`: CSV íŒŒì¼ ë¡œë“œ<br>- `create_train()`: Feature ì¶”ì¶œ<br>- `create_label()`: Label ì¶”ì¶œ |
| `titanic_service.py` | ML íŒŒì´í”„ë¼ì¸ | - `preprocess()`: ë°ì´í„° ì „ì²˜ë¦¬<br>- `modeling()`: ëª¨ë¸ ìƒì„±<br>- `learning()`: ëª¨ë¸ í•™ìŠµ<br>- `evaluate()`: ì„±ëŠ¥ í‰ê°€<br>- `submit()`: ê²°ê³¼ ì œì¶œ |
| `router.py` | API ì—”ë“œí¬ì¸íŠ¸ | - FastAPI ë¼ìš°í„°<br>- CRUD ì—”ë“œí¬ì¸íŠ¸<br>- ML ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸ |

---

## ì£¼ìš” ì»´í¬ë„ŒíŠ¸ ì„¤ëª…

### 1. Dataset í´ë˜ìŠ¤ (`titanic_dataset.py`)

ë°ì´í„°ì…‹ì˜ ë©”íƒ€ì •ë³´ì™€ DataFrameì„ ê´€ë¦¬í•˜ëŠ” ì»¨í…Œì´ë„ˆ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
@dataclass
class TitanicDataset(object):
    _fname: str = ''           # íŒŒì¼ëª… (ì˜ˆ: 'train.csv')
    _dname: str = ''           # ë°ì´í„° ê²½ë¡œ (ì˜ˆ: '/app/titanic/')
    _sname: str = ''           # ì €ì¥ ê²½ë¡œ (ì˜ˆ: '/app/results/')
    _train: pd.DataFrame = None  # í•™ìŠµ ë°ì´í„°í”„ë ˆì„
    _test: pd.DataFrame = None   # í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„
    _id: str = ''              # ID ì»¬ëŸ¼ëª… (ì˜ˆ: 'PassengerId')
    _label: str = ''           # ë¼ë²¨ ì»¬ëŸ¼ëª… (ì˜ˆ: 'Survived')
    
    # getter/setter ë©”ì„œë“œë“¤...
```

**ì‚¬ìš© ëª©ì **:
- ë°ì´í„° ê²½ë¡œ ê´€ë¦¬
- DataFrame ê°ì²´ ì €ì¥
- ë°ì´í„°ì…‹ ë©”íƒ€ì •ë³´ ìº¡ìŠí™”

### 2. Model í´ë˜ìŠ¤ (`titanic_model.py`)

ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
class TitanicModels:
    def __init__(self) -> None:
        pass
    
    # í–¥í›„ ì¶”ê°€ë  ë©”ì„œë“œë“¤:
    # - def random_forest_model(self, params): ...
    # - def xgboost_model(self, params): ...
    # - def neural_network_model(self, params): ...
```

**ì‚¬ìš© ëª©ì **:
- ë‹¤ì–‘í•œ ML ì•Œê³ ë¦¬ì¦˜ ì •ì˜
- ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê´€ë¦¬
- ëª¨ë¸ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥

### 3. Method í´ë˜ìŠ¤ (`titanic_method.py`)

ë°ì´í„° ì „ì²˜ë¦¬ ë° ê°€ê³µ ë©”ì„œë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```python
class TitanicMethod(object):
    def new_model(self):
        # train.csv íŒŒì¼ì„ ì½ì–´ì™€ì„œ DataFrame ìƒì„±
        pass
    
    def create_train(self):
        # Feature ë°ì´í„° ìƒì„± (Survived ì œì™¸)
        pass
    
    def create_label(self):
        # Label ë°ì´í„° ìƒì„± (Survivedë§Œ ì¶”ì¶œ)
        pass
```

**ì‚¬ìš© ëª©ì **:
- CSV íŒŒì¼ ë¡œë“œ
- Feature/Label ë¶„ë¦¬
- ë°ì´í„° í´ë Œì§• ë° ë³€í™˜

### 4. Service í´ë˜ìŠ¤ (`titanic_service.py`)

ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

```python
class TitanicService:
    def preprocess(self):
        # ë°ì´í„° ì „ì²˜ë¦¬ (ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì¸ì½”ë”© ë“±)
        ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì‹œì‘")
        ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì™„ë£Œ")
    
    def modeling(self):
        # ëª¨ë¸ ìƒì„± ë° ì„¤ì •
        ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì‹œì‘")
        ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì™„ë£Œ")
    
    def learning(self):
        # ëª¨ë¸ í•™ìŠµ
        ic("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì‹œì‘")
        ic("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì™„ë£Œ")
    
    def evaluate(self):
        # ëª¨ë¸ í‰ê°€ (ì •í™•ë„, F1-Score ë“±)
        ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì‹œì‘")
        ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì™„ë£Œ")
    
    def submit(self):
        # ê²°ê³¼ ì œì¶œ (CSV íŒŒì¼ ìƒì„± ë“±)
        ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì‹œì‘")
        ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì™„ë£Œ")
```

**ì‚¬ìš© ëª©ì **:
- ML íŒŒì´í”„ë¼ì¸ 5ë‹¨ê³„ ì‹¤í–‰
- ë‹¨ê³„ë³„ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
- ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§

### 5. Router (`router.py`)

FastAPI ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

```python
router = APIRouter(prefix="/titanic", tags=["titanic"])

# CRUD ì—”ë“œí¬ì¸íŠ¸
@router.get("/passengers")
async def get_all_passengers(): ...

# ML ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸ (í–¥í›„ ì¶”ê°€)
@router.post("/ml/preprocess")
async def run_preprocess(): ...

@router.post("/ml/train")
async def run_training(): ...

@router.get("/ml/evaluate")
async def get_evaluation(): ...
```

---

## ìƒˆë¡œìš´ CSV ë°ì´í„° ì—°ë™ ì›Œí¬í”Œë¡œìš°

### ì „ì²´ íë¦„ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CSV íŒŒì¼ ì¤€ë¹„                                â”‚
    â”‚  - train.csv (í•™ìŠµ ë°ì´í„°)                    â”‚
    â”‚  - test.csv (í…ŒìŠ¤íŠ¸ ë°ì´í„°)                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  2. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  mlservice/app/{dataset_name}/ í´ë” ìƒì„±     â”‚
    â”‚  â”œâ”€â”€ {dataset}_dataset.py                   â”‚
    â”‚  â”œâ”€â”€ {dataset}_model.py                     â”‚
    â”‚  â”œâ”€â”€ {dataset}_method.py                    â”‚
    â”‚  â”œâ”€â”€ {dataset}_service.py                   â”‚
    â”‚  â”œâ”€â”€ router.py                              â”‚
    â”‚  â”œâ”€â”€ train.csv                              â”‚
    â”‚  â””â”€â”€ test.csv                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  3. í´ë˜ìŠ¤ êµ¬í˜„ ë‹¨ê³„                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Dataset í´ë˜ìŠ¤ êµ¬í˜„   â”‚  â”‚  Method í´ë˜ìŠ¤ êµ¬í˜„    â”‚
    â”‚  - íŒŒì¼ ê²½ë¡œ ì„¤ì •      â”‚  â”‚  - CSV ë¡œë“œ êµ¬í˜„      â”‚
    â”‚  - DataFrame ì €ì¥     â”‚  â”‚  - Feature ë¶„ë¦¬       â”‚
    â”‚  - ID/Label ì •ì˜      â”‚  â”‚  - Label ë¶„ë¦¬         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Model í´ë˜ìŠ¤ êµ¬í˜„     â”‚  â”‚  Service í´ë˜ìŠ¤ êµ¬í˜„   â”‚
    â”‚  - ML ì•Œê³ ë¦¬ì¦˜ ì„ íƒ    â”‚  â”‚  - ì „ì²˜ë¦¬ ë¡œì§        â”‚
    â”‚  - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • â”‚  â”‚  - í•™ìŠµ ë¡œì§         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  - í‰ê°€ ë¡œì§         â”‚
                              â”‚  - ì œì¶œ ë¡œì§         â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  4. API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  router.py êµ¬í˜„                              â”‚
    â”‚  - CRUD ì—”ë“œí¬ì¸íŠ¸                           â”‚
    â”‚  - ML ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸                        â”‚
    â”‚  - í†µê³„/ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  5. main.pyì— ë¼ìš°í„° ë“±ë¡                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  app.include_router(                         â”‚
    â”‚      {dataset}_router,                       â”‚
    â”‚      prefix="",                              â”‚
    â”‚      tags=["{dataset}"]                      â”‚
    â”‚  )                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  6. í…ŒìŠ¤íŠ¸ ë° ë°°í¬                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Postman í…ŒìŠ¤íŠ¸       â”‚  â”‚  Docker ë¹Œë“œ         â”‚
    â”‚  - API ë™ì‘ í™•ì¸      â”‚  â”‚  - docker compose up â”‚
    â”‚  - ML íŒŒì´í”„ë¼ì¸ ê²€ì¦ â”‚  â”‚  - ì»¨í…Œì´ë„ˆ ì‹¤í–‰     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ìƒì„¸ ë‹¨ê³„ë³„ ê°€ì´ë“œ

#### Step 1: ë°ì´í„° ì¤€ë¹„

```bash
# 1. CSV íŒŒì¼ ì¤€ë¹„
# - train.csv: í•™ìŠµìš© ë°ì´í„° (ë¼ë²¨ í¬í•¨)
# - test.csv: í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° (ë¼ë²¨ ì œì™¸ ë˜ëŠ” ì˜ˆì¸¡ ëŒ€ìƒ)

# 2. ë°ì´í„° íƒìƒ‰
# - ì»¬ëŸ¼ í™•ì¸
# - ê²°ì¸¡ì¹˜ í™•ì¸
# - ë°ì´í„° íƒ€ì… í™•ì¸
# - ID ì»¬ëŸ¼ê³¼ Label ì»¬ëŸ¼ ì‹ë³„
```

#### Step 2: í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

```bash
# ì˜ˆì‹œ: housing(ì£¼íƒ ê°€ê²© ì˜ˆì¸¡) ë°ì´í„°ì…‹ ì¶”ê°€

cd mlservice/app
mkdir housing
cd housing

# íŒŒì¼ ìƒì„±
touch housing_dataset.py
touch housing_model.py
touch housing_method.py
touch housing_service.py
touch router.py
touch __init__.py

# CSV íŒŒì¼ ë³µì‚¬
cp /path/to/housing_train.csv ./train.csv
cp /path/to/housing_test.csv ./test.csv
```

#### Step 3: Dataset í´ë˜ìŠ¤ êµ¬í˜„

```python
# housing_dataset.py

from dataclasses import dataclass
import pandas as pd

@dataclass
class HousingDataset(object):
    _fname: str = ''  # file name
    _dname: str = ''  # data path
    _sname: str = ''  # save path
    _train: pd.DataFrame = None
    _test: pd.DataFrame = None
    _id: str = 'Id'  # ë°ì´í„°ì…‹ì˜ ID ì»¬ëŸ¼ëª…
    _label: str = 'SalePrice'  # ë°ì´í„°ì…‹ì˜ ë¼ë²¨ ì»¬ëŸ¼ëª…
    
    @property
    def fname(self) -> str:
        return self._fname
    
    @fname.setter
    def fname(self, fname):
        self._fname = fname
    
    # ... (ë‚˜ë¨¸ì§€ getter/setter ë©”ì„œë“œë“¤)
```

#### Step 4: Method í´ë˜ìŠ¤ êµ¬í˜„

```python
# housing_method.py

import pandas as pd
import os
from pathlib import Path

class HousingMethod(object):
    def __init__(self, dataset):
        self.dataset = dataset
    
    def new_model(self):
        """CSV íŒŒì¼ì„ ì½ì–´ì™€ì„œ DataFrame ìƒì„±"""
        train_path = Path(__file__).parent / "train.csv"
        test_path = Path(__file__).parent / "test.csv"
        
        self.dataset.train = pd.read_csv(train_path)
        self.dataset.test = pd.read_csv(test_path)
        
        return self.dataset
    
    def create_train(self):
        """Feature ë°ì´í„° ìƒì„± (ë¼ë²¨ ì œì™¸)"""
        if self.dataset.train is None:
            raise ValueError("Train data not loaded")
        
        # ë¼ë²¨ ì»¬ëŸ¼ ì œì™¸
        X_train = self.dataset.train.drop(
            columns=[self.dataset.label]
        )
        return X_train
    
    def create_label(self):
        """Label ë°ì´í„° ìƒì„±"""
        if self.dataset.train is None:
            raise ValueError("Train data not loaded")
        
        # ë¼ë²¨ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
        y_train = self.dataset.train[self.dataset.label]
        return y_train
```

#### Step 5: Service í´ë˜ìŠ¤ êµ¬í˜„

```python
# housing_service.py

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from icecream import ic

class HousingService:
    def __init__(self):
        self.dataset = None
        self.method = None
        self.model = None
        self.X_train = None
        self.y_train = None
        self.predictions = None
    
    def preprocess(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì‹œì‘")
        
        # 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        # 2. ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
        # 3. í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
        # 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
        
        ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì™„ë£Œ")
        return self
    
    def modeling(self):
        """ëª¨ë¸ ìƒì„±"""
        ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì‹œì‘")
        
        # RandomForest Regressor ìƒì„±
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        
        ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì™„ë£Œ")
        return self
    
    def learning(self):
        """ëª¨ë¸ í•™ìŠµ"""
        ic("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì‹œì‘")
        
        if self.model is None:
            raise ValueError("Model not created")
        
        # ëª¨ë¸ í•™ìŠµ
        self.model.fit(self.X_train, self.y_train)
        
        ic("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì™„ë£Œ")
        return self
    
    def evaluate(self):
        """ëª¨ë¸ í‰ê°€"""
        ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì‹œì‘")
        
        # ì˜ˆì¸¡
        predictions = self.model.predict(self.X_train)
        
        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        mse = mean_squared_error(self.y_train, predictions)
        r2 = r2_score(self.y_train, predictions)
        
        ic(f"MSE: {mse}")
        ic(f"R2 Score: {r2}")
        
        ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì™„ë£Œ")
        return {"mse": mse, "r2": r2}
    
    def submit(self):
        """ê²°ê³¼ ì œì¶œ (CSV ìƒì„±)"""
        ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì‹œì‘")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
        test_predictions = self.model.predict(self.X_test)
        
        # ì œì¶œ íŒŒì¼ ìƒì„±
        submission = pd.DataFrame({
            self.dataset.id: self.dataset.test[self.dataset.id],
            self.dataset.label: test_predictions
        })
        
        # CSV ì €ì¥
        submission.to_csv("submission.csv", index=False)
        
        ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì™„ë£Œ")
        return submission
```

#### Step 6: Router êµ¬í˜„

```python
# router.py

from fastapi import APIRouter, HTTPException
from typing import Dict, Any
from app.housing.housing_dataset import HousingDataset
from app.housing.housing_method import HousingMethod
from app.housing.housing_service import HousingService

router = APIRouter(prefix="/housing", tags=["housing"])

# ML íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸
@router.post("/ml/preprocess")
async def run_preprocess():
    """ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰"""
    try:
        service = HousingService()
        service.preprocess()
        return {"status": "success", "message": "ì „ì²˜ë¦¬ ì™„ë£Œ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/ml/train")
async def run_training():
    """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    try:
        service = HousingService()
        service.preprocess()
        service.modeling()
        service.learning()
        return {"status": "success", "message": "í•™ìŠµ ì™„ë£Œ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/ml/evaluate")
async def get_evaluation():
    """ëª¨ë¸ í‰ê°€ ê²°ê³¼ ì¡°íšŒ"""
    try:
        service = HousingService()
        # ... (ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰)
        results = service.evaluate()
        return {"status": "success", "results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/ml/submit")
async def create_submission():
    """ì œì¶œ íŒŒì¼ ìƒì„±"""
    try:
        service = HousingService()
        # ... (ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰)
        submission = service.submit()
        return {
            "status": "success", 
            "message": "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ",
            "rows": len(submission)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë°ì´í„° ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
@router.get("/data/info")
async def get_data_info():
    """ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ"""
    dataset = HousingDataset()
    method = HousingMethod(dataset)
    method.new_model()
    
    return {
        "train_shape": dataset.train.shape,
        "test_shape": dataset.test.shape,
        "columns": list(dataset.train.columns),
        "id_column": dataset.id,
        "label_column": dataset.label
    }

@router.get("/data/stats")
async def get_data_stats():
    """ë°ì´í„° í†µê³„ ì •ë³´"""
    dataset = HousingDataset()
    method = HousingMethod(dataset)
    method.new_model()
    
    return {
        "describe": dataset.train.describe().to_dict(),
        "missing_values": dataset.train.isnull().sum().to_dict()
    }
```

#### Step 7: main.pyì— ë¼ìš°í„° ë“±ë¡

```python
# app/main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# ê¸°ì¡´ ë¼ìš°í„°
from app.titanic.router import router as titanic_router

# ìƒˆë¡œìš´ ë¼ìš°í„° ì¶”ê°€
from app.housing.router import router as housing_router

app = FastAPI(
    title="ML Service",
    description="ë¨¸ì‹ ëŸ¬ë‹ í†µí•© ì„œë¹„ìŠ¤",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# íƒ€ì´íƒ€ë‹‰ ë¼ìš°í„° ë“±ë¡
app.include_router(
    titanic_router,
    prefix="",
    tags=["titanic"]
)

# ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ ë¼ìš°í„° ë“±ë¡
app.include_router(
    housing_router,
    prefix="",
    tags=["housing"]
)

@app.get("/")
async def root():
    return {
        "service": "ML Service",
        "status": "running",
        "endpoints": {
            "titanic": "/titanic",
            "housing": "/housing",  # ìƒˆë¡œ ì¶”ê°€
            "docs": "/docs"
        }
    }
```

#### Step 8: í…ŒìŠ¤íŠ¸

```bash
# 1. Docker ë¹Œë“œ ë° ì‹¤í–‰
cd mlservice
docker compose up -d --build

# 2. API ë™ì‘ í™•ì¸
curl http://localhost:9006/

# 3. Swagger UI í™•ì¸
# http://localhost:9006/docs

# 4. ë°ì´í„° ì •ë³´ í™•ì¸
curl http://localhost:9006/housing/data/info

# 5. ML íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
curl -X POST http://localhost:9006/housing/ml/preprocess
curl -X POST http://localhost:9006/housing/ml/train
curl http://localhost:9006/housing/ml/evaluate
curl -X POST http://localhost:9006/housing/ml/submit
```

---

## ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°

### 5ë‹¨ê³„ íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ML Pipeline 5 Stages                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Preprocess (ì „ì²˜ë¦¬)
   â”œâ”€â”€ ë°ì´í„° ë¡œë“œ
   â”œâ”€â”€ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
   â”œâ”€â”€ ì´ìƒì¹˜ ì œê±°
   â”œâ”€â”€ í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
   â””â”€â”€ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
          â†“
2. Modeling (ëª¨ë¸ë§)
   â”œâ”€â”€ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ
   â”œâ”€â”€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
   â”œâ”€â”€ êµì°¨ ê²€ì¦ ì„¤ì •
   â””â”€â”€ ì•™ìƒë¸” êµ¬ì„±
          â†“
3. Learning (í•™ìŠµ)
   â”œâ”€â”€ ëª¨ë¸ í•™ìŠµ
   â”œâ”€â”€ íŒŒë¼ë¯¸í„° ìµœì í™”
   â”œâ”€â”€ í•™ìŠµ ê³¡ì„  ëª¨ë‹ˆí„°ë§
   â””â”€â”€ ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
          â†“
4. Evaluate (í‰ê°€)
   â”œâ”€â”€ ì˜ˆì¸¡ ìˆ˜í–‰
   â”œâ”€â”€ í‰ê°€ ì§€í‘œ ê³„ì‚°
   â”‚   â”œâ”€â”€ íšŒê·€: MSE, RMSE, R2, MAE
   â”‚   â””â”€â”€ ë¶„ë¥˜: Accuracy, Precision, Recall, F1, AUC
   â”œâ”€â”€ í˜¼ë™ í–‰ë ¬ ìƒì„±
   â””â”€â”€ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
          â†“
5. Submit (ì œì¶œ)
   â”œâ”€â”€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
   â”œâ”€â”€ ì œì¶œ íŒŒì¼ ìƒì„±
   â”œâ”€â”€ ê²°ê³¼ ê²€ì¦
   â””â”€â”€ CSV íŒŒì¼ ì €ì¥
```

### ê° ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ

#### 1. Preprocess (ì „ì²˜ë¦¬)

```python
def preprocess(self):
    ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì‹œì‘")
    
    # 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    self.handle_missing_values()
    
    # 2. ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©
    self.encode_categorical_features()
    
    # 3. ìˆ˜ì¹˜í˜• í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
    self.scale_numerical_features()
    
    # 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    self.engineer_features()
    
    ic("ğŸ˜ŠğŸ˜Š ì „ì²˜ë¦¬ ì™„ë£Œ")
    return self

def handle_missing_values(self):
    """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    # ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    numeric_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns
    self.X_train[numeric_cols] = self.X_train[numeric_cols].fillna(
        self.X_train[numeric_cols].median()
    )
    
    # ì¹´í…Œê³ ë¦¬í˜•: ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ìš°ê¸°
    categorical_cols = self.X_train.select_dtypes(include=['object']).columns
    self.X_train[categorical_cols] = self.X_train[categorical_cols].fillna(
        self.X_train[categorical_cols].mode().iloc[0]
    )

def encode_categorical_features(self):
    """ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”©"""
    from sklearn.preprocessing import LabelEncoder
    
    categorical_cols = self.X_train.select_dtypes(include=['object']).columns
    
    for col in categorical_cols:
        le = LabelEncoder()
        self.X_train[col] = le.fit_transform(self.X_train[col].astype(str))

def scale_numerical_features(self):
    """ìˆ˜ì¹˜í˜• í”¼ì²˜ ìŠ¤ì¼€ì¼ë§"""
    from sklearn.preprocessing import StandardScaler
    
    numeric_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns
    
    scaler = StandardScaler()
    self.X_train[numeric_cols] = scaler.fit_transform(self.X_train[numeric_cols])

def engineer_features(self):
    """í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
    # ì˜ˆ: ê°€ì¡± í¬ê¸° = SibSp + Parch + 1
    if 'SibSp' in self.X_train.columns and 'Parch' in self.X_train.columns:
        self.X_train['FamilySize'] = (
            self.X_train['SibSp'] + self.X_train['Parch'] + 1
        )
```

#### 2. Modeling (ëª¨ë¸ë§)

```python
def modeling(self):
    ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì‹œì‘")
    
    # 1. ë‹¨ì¼ ëª¨ë¸
    self.create_single_model()
    
    # ë˜ëŠ” 2. ì•™ìƒë¸” ëª¨ë¸
    # self.create_ensemble_model()
    
    ic("ğŸ˜ŠğŸ˜Š ëª¨ë¸ë§ ì™„ë£Œ")
    return self

def create_single_model(self):
    """ë‹¨ì¼ ëª¨ë¸ ìƒì„±"""
    from sklearn.ensemble import RandomForestClassifier
    
    self.model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )

def create_ensemble_model(self):
    """ì•™ìƒë¸” ëª¨ë¸ ìƒì„±"""
    from sklearn.ensemble import VotingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.svm import SVC
    
    # ì—¬ëŸ¬ ëª¨ë¸ ìƒì„±
    lr = LogisticRegression(random_state=42)
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    svc = SVC(probability=True, random_state=42)
    
    # íˆ¬í‘œ ì•™ìƒë¸”
    self.model = VotingClassifier(
        estimators=[('lr', lr), ('rf', rf), ('svc', svc)],
        voting='soft'
    )
```

#### 3. Learning (í•™ìŠµ)

```python
def learning(self):
    ic("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì‹œì‘")
    
    if self.model is None:
        raise ValueError("Model not created")
    
    # 1. ëª¨ë¸ í•™ìŠµ
    self.model.fit(self.X_train, self.y_train)
    
    # 2. í•™ìŠµ ì •ë³´ ê¸°ë¡
    self.log_training_info()
    
    ic("ğŸ˜ŠğŸ˜Š í•™ìŠµ ì™„ë£Œ")
    return self

def log_training_info(self):
    """í•™ìŠµ ì •ë³´ ë¡œê¹…"""
    ic(f"Model: {type(self.model).__name__}")
    ic(f"Train samples: {len(self.X_train)}")
    
    # RandomForestì˜ ê²½ìš° í”¼ì²˜ ì¤‘ìš”ë„ ê¸°ë¡
    if hasattr(self.model, 'feature_importances_'):
        importances = self.model.feature_importances_
        feature_names = self.X_train.columns
        
        feature_importance = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        ic(feature_importance.head(10))
```

#### 4. Evaluate (í‰ê°€)

```python
def evaluate(self):
    ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì‹œì‘")
    
    # 1. ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = self.model.predict(self.X_train)
    
    # 2. í‰ê°€ ì§€í‘œ ê³„ì‚°
    metrics = self.calculate_metrics(self.y_train, predictions)
    
    # 3. í˜¼ë™ í–‰ë ¬ (ë¶„ë¥˜ ë¬¸ì œ)
    self.plot_confusion_matrix(self.y_train, predictions)
    
    ic("ğŸ˜ŠğŸ˜Š í‰ê°€ ì™„ë£Œ")
    return metrics

def calculate_metrics(self, y_true, y_pred):
    """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
    from sklearn.metrics import (
        accuracy_score, precision_score, recall_score, 
        f1_score, classification_report
    )
    
    metrics = {
        "accuracy": accuracy_score(y_true, y_pred),
        "precision": precision_score(y_true, y_pred, average='weighted'),
        "recall": recall_score(y_true, y_pred, average='weighted'),
        "f1_score": f1_score(y_true, y_pred, average='weighted')
    }
    
    ic(metrics)
    
    # ìƒì„¸ ë¦¬í¬íŠ¸
    report = classification_report(y_true, y_pred)
    ic(report)
    
    return metrics

def plot_confusion_matrix(self, y_true, y_pred):
    """í˜¼ë™ í–‰ë ¬ ì‹œê°í™”"""
    from sklearn.metrics import confusion_matrix
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig('confusion_matrix.png')
    
    ic("Confusion matrix saved to confusion_matrix.png")
```

#### 5. Submit (ì œì¶œ)

```python
def submit(self):
    ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì‹œì‘")
    
    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•˜ê²Œ)
    X_test = self.preprocess_test_data()
    
    # 2. ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = self.model.predict(X_test)
    
    # 3. ì œì¶œ íŒŒì¼ ìƒì„±
    submission = self.create_submission_file(predictions)
    
    # 4. ê²€ì¦
    self.validate_submission(submission)
    
    # 5. ì €ì¥
    submission.to_csv("submission.csv", index=False)
    
    ic("ğŸ˜ŠğŸ˜Š ì œì¶œ ì™„ë£Œ")
    return submission

def preprocess_test_data(self):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬"""
    # í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©
    X_test = self.dataset.test.copy()
    
    # ID ì»¬ëŸ¼ ì œê±°
    if self.dataset.id in X_test.columns:
        X_test = X_test.drop(columns=[self.dataset.id])
    
    # ë™ì¼í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì ìš©
    # ... (ê²°ì¸¡ì¹˜, ì¸ì½”ë”©, ìŠ¤ì¼€ì¼ë§ ë“±)
    
    return X_test

def create_submission_file(self, predictions):
    """ì œì¶œ íŒŒì¼ ìƒì„±"""
    submission = pd.DataFrame({
        self.dataset.id: self.dataset.test[self.dataset.id],
        self.dataset.label: predictions
    })
    
    return submission

def validate_submission(self, submission):
    """ì œì¶œ íŒŒì¼ ê²€ì¦"""
    ic(f"Submission shape: {submission.shape}")
    ic(f"Columns: {list(submission.columns)}")
    ic(f"First 5 rows:\n{submission.head()}")
    
    # ê²°ì¸¡ì¹˜ í™•ì¸
    if submission.isnull().any().any():
        ic("Warning: Submission contains null values!")
    
    # ID ì¤‘ë³µ í™•ì¸
    if submission[self.dataset.id].duplicated().any():
        ic("Warning: Submission contains duplicate IDs!")
```

---

## API ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„ ê°€ì´ë“œ

### ì—”ë“œí¬ì¸íŠ¸ ë„¤ì´ë° ê·œì¹™

```
/{dataset_name}/           # ë°ì´í„°ì…‹ ë£¨íŠ¸
â”œâ”€â”€ /data/                 # ë°ì´í„° ê´€ë ¨
â”‚   â”œâ”€â”€ /info              # ë°ì´í„° ì •ë³´
â”‚   â”œâ”€â”€ /stats             # í†µê³„ ì •ë³´
â”‚   â””â”€â”€ /sample            # ìƒ˜í”Œ ë°ì´í„°
â”‚
â”œâ”€â”€ /ml/                   # ML íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ /preprocess        # ì „ì²˜ë¦¬ ì‹¤í–‰
â”‚   â”œâ”€â”€ /train             # í•™ìŠµ ì‹¤í–‰
â”‚   â”œâ”€â”€ /evaluate          # í‰ê°€ ì¡°íšŒ
â”‚   â”œâ”€â”€ /submit            # ì œì¶œ íŒŒì¼ ìƒì„±
â”‚   â””â”€â”€ /pipeline          # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
â”‚
â””â”€â”€ /model/                # ëª¨ë¸ ê´€ë¦¬
    â”œâ”€â”€ /save              # ëª¨ë¸ ì €ì¥
    â”œâ”€â”€ /load              # ëª¨ë¸ ë¡œë“œ
    â””â”€â”€ /list              # ëª¨ë¸ ëª©ë¡
```

### ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ í…œí”Œë¦¿

```python
# router.py

from fastapi import APIRouter, HTTPException, Query
from typing import Dict, Any, Optional

router = APIRouter(prefix="/{dataset_name}", tags=["{dataset_name}"])

# ==================== ë°ì´í„° ê´€ë ¨ ====================

@router.get("/data/info")
async def get_data_info():
    """ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´"""
    return {
        "train_shape": (rows, cols),
        "test_shape": (rows, cols),
        "columns": ["col1", "col2", ...],
        "id_column": "Id",
        "label_column": "Label"
    }

@router.get("/data/stats")
async def get_data_stats():
    """ë°ì´í„° í†µê³„ ì •ë³´"""
    return {
        "describe": {...},
        "missing_values": {...},
        "data_types": {...}
    }

@router.get("/data/sample")
async def get_data_sample(n: int = Query(5, ge=1, le=100)):
    """ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ"""
    return {
        "train_sample": [...],
        "test_sample": [...]
    }

# ==================== ML íŒŒì´í”„ë¼ì¸ ====================

@router.post("/ml/preprocess")
async def run_preprocess():
    """ì „ì²˜ë¦¬ ì‹¤í–‰"""
    return {"status": "success", "message": "ì „ì²˜ë¦¬ ì™„ë£Œ"}

@router.post("/ml/train")
async def run_training(
    model_type: str = Query("random_forest"),
    params: Optional[Dict[str, Any]] = None
):
    """ëª¨ë¸ í•™ìŠµ ì‹¤í–‰"""
    return {
        "status": "success",
        "message": "í•™ìŠµ ì™„ë£Œ",
        "model_type": model_type,
        "training_time": 123.45
    }

@router.get("/ml/evaluate")
async def get_evaluation():
    """í‰ê°€ ê²°ê³¼ ì¡°íšŒ"""
    return {
        "status": "success",
        "metrics": {
            "accuracy": 0.85,
            "precision": 0.83,
            "recall": 0.87,
            "f1_score": 0.85
        }
    }

@router.post("/ml/submit")
async def create_submission():
    """ì œì¶œ íŒŒì¼ ìƒì„±"""
    return {
        "status": "success",
        "message": "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ",
        "file_path": "submission.csv",
        "rows": 418
    }

@router.post("/ml/pipeline")
async def run_full_pipeline(
    model_type: str = Query("random_forest"),
    save_model: bool = Query(True)
):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì „ì²˜ë¦¬ â†’ í•™ìŠµ â†’ í‰ê°€ â†’ ì œì¶œ)"""
    return {
        "status": "success",
        "steps": {
            "preprocess": "completed",
            "modeling": "completed",
            "learning": "completed",
            "evaluate": "completed",
            "submit": "completed"
        },
        "metrics": {...},
        "submission_file": "submission.csv"
    }

# ==================== ëª¨ë¸ ê´€ë¦¬ ====================

@router.post("/model/save")
async def save_model(model_name: str = Query(...)):
    """ëª¨ë¸ ì €ì¥"""
    return {
        "status": "success",
        "message": f"ëª¨ë¸ '{model_name}' ì €ì¥ ì™„ë£Œ",
        "file_path": f"models/{model_name}.pkl"
    }

@router.post("/model/load")
async def load_model(model_name: str = Query(...)):
    """ëª¨ë¸ ë¡œë“œ"""
    return {
        "status": "success",
        "message": f"ëª¨ë¸ '{model_name}' ë¡œë“œ ì™„ë£Œ",
        "model_info": {...}
    }

@router.get("/model/list")
async def list_models():
    """ì €ì¥ëœ ëª¨ë¸ ëª©ë¡"""
    return {
        "models": [
            {"name": "model1", "created_at": "2024-12-05", "size": "1.2MB"},
            {"name": "model2", "created_at": "2024-12-04", "size": "2.5MB"}
        ]
    }
```

---

## ìš”ì•½

### í•µì‹¬ í¬ì¸íŠ¸

1. **ëª¨ë“ˆí™”ëœ êµ¬ì¡°**: ê° ë°ì´í„°ì…‹ì€ ë…ë¦½ì ì¸ ëª¨ë“ˆë¡œ ê´€ë¦¬
2. **ì¼ê´€ëœ íŒŒì¼ êµ¬ì¡°**: Dataset, Model, Method, Service, Router
3. **5ë‹¨ê³„ ML íŒŒì´í”„ë¼ì¸**: Preprocess â†’ Modeling â†’ Learning â†’ Evaluate â†’ Submit
4. **í™•ì¥ ê°€ëŠ¥ì„±**: ìƒˆ ë°ì´í„°ì…‹ ì¶”ê°€ ì‹œ ê¸°ì¡´ êµ¬ì¡° ë³µì‚¬ í›„ ìˆ˜ì •
5. **API ìš°ì„  ì„¤ê³„**: FastAPIë¥¼ í†µí•œ RESTful API ì œê³µ

### ë‹¤ìŒ ë‹¨ê³„

- [ ] ì¶”ê°€ ë°ì´í„°ì…‹ êµ¬í˜„ (Culture, Housing ë“±)
- [ ] ê³µí†µ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤ ê°œë°œ
- [ ] ëª¨ë¸ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ì‹¤ì‹œê°„ í•™ìŠµ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
- [ ] AutoML ê¸°ëŠ¥ í†µí•©

---

## ì°¸ê³  ìë£Œ

- [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com/)
- [Scikit-learn ë¬¸ì„œ](https://scikit-learn.org/)
- [Pandas ë¬¸ì„œ](https://pandas.pydata.org/)
- [Docker Compose ë¬¸ì„œ](https://docs.docker.com/compose/)

---

**ì‘ì„±ì¼**: 2024-12-05  
**ë²„ì „**: 1.0.0  
**ì‘ì„±ì**: ML Service Team

